# Q&A Chatbot with RAG and SQL Agents

A powerful chatbot that combines Retrieval-Augmented Generation (RAG) and SQL agents to answer questions from both unstructured documents and structured databases. It features smart query routing, hybrid retrieval, and seamless integration with local and cloud-based LLMs.

---

## ðŸš€ Overview

This project implements a multi-agent natural language Q&A system that can:

- ðŸ§¾ Process **unstructured data** (PDFs) using **RAG**
- ðŸ§® Query **structured data** (CSV â†’ SQLite) using **SQL**
- ðŸ§  Intelligently **route queries** to the correct agent based on intent
- ðŸ’¬ Provide **context-aware, accurate answers** using advanced language models

The system uses **Unstructured.io** for document parsing and **ChromaDB** for vector search. A primary agent delegates user queries to specialized agents.

---

## ðŸ—ï¸ Architecture

```text
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   User      â”‚
            â”‚   Query     â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Primary Agent   â”‚
        â”‚  (Query Classifier) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Agent   â”‚    â”‚    SQL Agent    â”‚
â”‚ (Unstructured â”‚    â”‚   (Structured   â”‚
â”‚  Data: PDFs)  â”‚    â”‚      Data)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ Retrieve Docs         â”‚ Execute SQL
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChromaDB     â”‚    â”‚     SQLite      â”‚
â”‚(Vector Store) â”‚    â”‚   Database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Primary Agent   â”‚
        â”‚  (Generate Response)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     User      â”‚
        â”‚    Answer     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

- **Multi-agent Architecture** â€“ Specialized RAG and SQL agents improve precision.
- **Hybrid Retrieval** â€“ Combines vector search and SQL for rich answers.
- **Smart Chunking** â€“ Uses Unstructured.io's `by_title` for semantically coherent document chunks.
- **Evaluation via RAGAS** â€“ Automated response quality scoring.
- **Gradio UI** â€“ Intuitive, web-based chat interface.
- **LLM Flexibility** â€“ Plug-and-play support for Hugging Face and Ollama (local models, preferred way).

---

## ðŸ“ Project Structure

```text
project/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdf_directory/
â”‚   â””â”€â”€ csv_directory/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ db_storage.py
â”‚   â”œâ”€â”€ chunk_creation.py
â”‚   â”œâ”€â”€ retrieval_strategy.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ primary_agent.py
â”‚   â”‚   â”œâ”€â”€ rag_agent.py
â”‚   â”‚   â””â”€â”€ sql_agent.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ report_generation.py
â”‚   â””â”€â”€ app.py
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

1. **Clone the repo**  
   ```bash
   git clone https://github.com/your/repo-name.git
   cd repo-name
   ```

2. **(Optional)** Create a virtual environment  
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

4. **(Optional)** Install Ollama for local LLMs  
   ```bash
   brew install ollama
   ollama serve
   ollama pull llama3
   ```

---

## ðŸ”§ Configuration

Edit `config.py` to customize:

- ðŸ“‚ Data directories
- ðŸ—„ï¸ Database paths
- ðŸ¤– LLM settings (Ollama vs Hugging Face)
- ðŸ“ Chunking parameters
- ðŸ” Retrieval strategy
- ðŸ“Š Evaluation metrics

---

## ðŸ“¥ Adding & Processing Data

### âž• Unstructured Data (PDFs)
Place PDFs in: `data/pdf_directory/`

### âž• Structured Data (CSVs)
Place CSVs in: `data/csv_directory/`  
(*Ensure first row has column headers*)

### ðŸ”„ Process All Data
```bash
python scripts/data_processing.py --pdf_dir data/pdf_directory --csv_dir data/csv_directory output.json
```

### ðŸ’¾ Store Processed Data
```bash
python scripts/db_storage.py output.json --sqlite_table my_data --chroma_collection my_collection
```

---

## ðŸ–¥ï¸ Running the App

Start the Gradio web interface:

```bash
python scripts/app.py
```

Visit the link in the terminal (usually `http://127.0.0.1:7860`).


---

## ðŸ§© Key Components

### ðŸ§± Chunking Strategy

Implemented in `chunk_creation.py`, using Unstructured.ioâ€™s `by_title` approach:

- Recognizes sections by headers
- Creates semantically meaningful chunks
- Preserves document hierarchy

### ðŸ” Retrieval Strategy

Defined in `retrieval_strategy.py`:

- Semantic search via ChromaDB
- Maximum Marginal Relevance (MMR)
- Customizable thresholds

### ðŸ§  Agent System

- `PrimaryAgent` â€“ Routes queries
- `RAGAgent` â€“ Handles unstructured docs
- `SQLAgent` â€“ Handles tabular data

---

## ðŸ“Š Evaluation with RAGAS

Evaluate chatbot responses on metrics like:

- **Faithfulness** (factual accuracy)
- **Answer Relevance**
- **Context Precision/Recall**


## ðŸ¤ Contributing

Pull requests are welcome!  
Suggestions for improvements, bug fixes, or new features are appreciated.

> Consider following a branch naming convention like `feature/`, `bugfix/`, or `docs/`.

---

## ðŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
